{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicio_Pascua_MLlib.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVEgGnSNYRJ-",
        "outputId": "2ebbb550-b1c6-4063-d802-7fa3994e5caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 32 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 55.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=cb05a8575e1d451ecfa5e158a2b93d1cb608d0194088d3b339cc26e34fd73dad\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "T17hd4yvYXDo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Creacion de la sesion y lectura de los datos\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('app').getOrCreate()\n",
        "df = spark.read.csv('/content/drive/MyDrive/Colab Notebooks/SAA/DATASETS/cereal.csv', header = True, inferSchema = True)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYk7YPIqZcxr",
        "outputId": "4e8d66e9-cd37-4fc3-df42-ba2ac6845c4b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- mfr: string (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- calories: integer (nullable = true)\n",
            " |-- protein: integer (nullable = true)\n",
            " |-- fat: integer (nullable = true)\n",
            " |-- sodium: integer (nullable = true)\n",
            " |-- fiber: double (nullable = true)\n",
            " |-- carbo: double (nullable = true)\n",
            " |-- sugars: integer (nullable = true)\n",
            " |-- potass: integer (nullable = true)\n",
            " |-- vitamins: integer (nullable = true)\n",
            " |-- shelf: integer (nullable = true)\n",
            " |-- weight: double (nullable = true)\n",
            " |-- cups: double (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Features\n",
        "df=df[[\"calories\",\"fiber\",\"sugars\",\"rating\"]]"
      ],
      "metadata": {
        "id": "uCGFz_yUYtLT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformacion a vectores\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.linalg import Vectors\n",
        "trainingData=df.rdd.map(lambda x:(Vectors.dense(x[0:-1]), x[-1])).toDF([\"features\", \"label\"])"
      ],
      "metadata": {
        "id": "inIymXjTbNDf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train-test split\n",
        "train, test = trainingData.randomSplit([0.7, 0.3], seed = 43)\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "print(\"Test Dataset Count: \" + str(test.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhfM-WsUZrTT",
        "outputId": "c5a37f7c-9053-44ef-8e46-c1eca9442cf3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 52\n",
            "Test Dataset Count: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo regresion lineal\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "\n",
        "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "\n",
        "# Fit the model\n",
        "lrModel = lr.fit(train)\n",
        "\n",
        "# Print the coefficients and intercept for linear regression\n",
        "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
        "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
        "\n",
        "# Summarize the model over the training set and print out some metrics\n",
        "trainingSummary = lrModel.summary\n",
        "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
        "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
        "print(\"r2: %f\" % trainingSummary.r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFdOdoyVaPN7",
        "outputId": "5953504c-c30e-4d5f-c36c-641c7fe0b07a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-0.12966964814549908,2.4599553518649344,-1.8011152310769376]\n",
            "Intercept: 63.68853155386343\n",
            "numIterations: 8\n",
            "RMSE: 5.321817\n",
            "r2: 0.861852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicciones con test\n",
        "lr_predictions = lrModel.transform(test)\n",
        "lr_predictions.select(\"prediction\",\"label\",\"features\").show(10)\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
        "                 labelCol=\"label\",metricName=\"r2\")\n",
        "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xURlk_mKbw7F",
        "outputId": "ffc7c092-992f-4264-af34-bcbe912dcb64"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------+----------------+\n",
            "|        prediction|    label|        features|\n",
            "+------------------+---------+----------------+\n",
            "| 57.20504914658847|60.756112|  [50.0,0.0,0.0]|\n",
            "| 60.69482575781831|68.235885|  [80.0,3.0,0.0]|\n",
            "| 46.13148253803675|55.333142|  [90.0,2.0,6.0]|\n",
            "| 59.39812927636331|72.801787|  [90.0,3.0,0.0]|\n",
            "|23.704838273159453|35.252444|[100.0,0.0,15.0]|\n",
            "| 49.57929162902458|45.863324| [100.0,1.0,2.0]|\n",
            "| 44.17594593579376|44.330856| [100.0,1.0,5.0]|\n",
            "| 44.83478605658176|45.328074| [100.0,2.0,6.0]|\n",
            "| 44.83478605658176|49.511874| [100.0,2.0,6.0]|\n",
            "| 52.69808710167751|46.658844| [100.0,3.0,3.0]|\n",
            "+------------------+---------+----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "R Squared (R2) on test data = 0.798318\n"
          ]
        }
      ]
    }
  ]
}